---
title: "Understanding KNN"
author: "Thomas Goossens"
date: "12/18/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
devtools::load_all()
```

## Intro

How does knn exactly works ? From masteringmachinelearning.com [post](https://machinelearningmastery.com/k-nearest-neighbors-for-machine-learning/) we have deciced to conduct a little test.

## Load the libraries

Here are all the libraries required for our investigation

```{r libraries}
# loading mlr & agrometeoR
library(FNN)
library(mlr)
library(agrometeoR)
library(dplyr)
library(sf)
library(mapview)
```

## Example dataset

We create an example dataset from our AGROMET weather database.
We extract an hourly observation of temperature for the 29 stations of the Pameseb AWS network.

```{r dataset creation}
user_token = Sys.getenv("AGROMET_API_V1_KEY")
dfrom = ex_dfrom
dto = ex_dto
stations = paste0(as.character(stations.df$sid), collapse = ",")
sensor = "tsa"
staticExpl = "elevation"

makeDataset.test = makeDataset(
  user_token = user_token,
  stations = stations,
  dfrom = dfrom,
  dto = dto,
  sensor = sensor,
  staticExpl = staticExpl
)
```

## Comparing various outputs of knn learners

We will compare the outputs of these 3 knn-based learners implemented in our package :

* lrn.gstat.5nn
* lrn.gstat.5nn.alt
* lrn.gstat.knn.alt.tuning

```{r}
learners.knn = list(
  lrn.gstat.5nn = am.learners$lrn.gstat.5nn,
  lrn.gstat.5nn.alt = am.learners$lrn.gstat.5nn.alt,
  lrn.gstat.knn.alt.tuning = am.learners$lrn.gstat.knn.alt.tuning)

task.knn = makeTasks(dataset = makeDataset.test$output$value, target = "tsa")

bmr.knn = makeBenchmark(tasks = task.knn$output$value[[1]], learners = learners.knn, measures = rmse, resamplings = "LOO")

models = lapply(X = learners.knn, function(x) {
  makeModel(task = task.knn$output$value[[1]],
    learner = x)
})

predictions = lapply(X = models, function(x) {
  makeSpatialization(model = x$output$value$trained)
})

maps = lapply(X = predictions, function(x) {
  plot(sf::st_as_sf(x$output$value, coords = c("X", "Y"))["response"])
})


```


Let's first define our train & test daatsets
```{r train-Test}
train = dataset[2:29,]
test = dataset[1:1,]

train.task = makeTasks(output$value$trained
  dataset = train,
  target = "tsa"
)
train.task = train.task$output$value
train.data = getTaskData(train.task[[1]])

test.task =  makeTasks(
  dataset = test,
  target = "tsa"
)
test.task = test.task$output$value
test.data = getTaskData(test.task[[1]])
```



We can now "train" our learner on the train set and use it to predict the value of the test set.



The learner we invoke here is a learner that comes prebuilt with the agrometeoR package. It's source code can be found in the [makeLearners.R](https://github.com/pokyah/agrometeoR/blob/master/data-raw/makeLearners.R) file on github

```{r training-and-predicting}
# training
train.model.5nn = mlr::train(
  learner = learners$lrn.gstat.5nn,
  task = train.task[[1]])

# predicting
test.pred.5nn = predict(train.model.5nn, test.task[[1]])

# adding predicted info to test set
test.data = test.data %>%
  dplyr::bind_cols(test.pred.5nn$data) %>%
  dplyr::mutate(residuals = truth - response)

# excerpt of the data
head(test.data)
```

We see that the gstat 5nn predicted value corresponds to `r test.data$response`
Let's make a manual computation to check if we get the same value !

## Manual computation

The manual computation is simple. We take the `tsa` value of the 5 stations which are closest to our excluded station and compute their mean. These stations id can be found using by filtering our dataset by the id that matche the id stored the columns V1, V2, V3, V4, V5.

```{r manual check}
manual_5NN = dataset %>%
  dplyr::filter(id %in% as.numeric(dataset[1,8:12])) %>%
  dplyr::summarise_at(.vars = "tsa", .funs = mean)

manual_5NN
```

We see that this manual computation provides the exact same value of the one provided by gstat ! 

## Conclusion

We can assert that the behaviour of the gstat learner correspond to our expectations. Also, we must note that we have define our gstat.5nn learner such as the values of the neighbours are not weighted according to their distance to the station for which we want to predict the value. Here is the code corresponding to the definition of our gstat.5nn learner (as found on github) : 

```{r}
  lrn.gstat.5nn = makeFilterWrapper(
    learner = makeLearner(
      cl = "regr.gstat",
      id = "nn5",
      par.vals = list(
        set = list(idp = 0),
        nmax = 5,
        debug.level = 0),
      predict.type = "se"),
    fw.method = "linear.correlation",
    fw.mandatory.feat = c("y", "x"),
    fw.abs = 2)
```

The line `set = list(idp = 0)` actually tells that values of the neighbours must not be weighted according to their distance to the station for which we want to predict the value.

Here below is a map of the used station and their values
```{r mapping}
dataset.sf = st_as_sf(dataset, coords = c("x","y"))
sf::st_crs(dataset.sf) = 3812

test.data.sf = st_as_sf(test.data, coords = c("x","y"))
sf::st_crs(test.data.sf) = 3812

train.data.sf = st_as_sf(train.data, coords = c("x","y"))
sf::st_crs(train.data.sf) = 3812

map = mapview::mapview(test.data.sf["response"]) + mapview::mapview(train.data.sf["tsa"]) + 
mapview::mapview(dataset.sf["id"])

map
```
