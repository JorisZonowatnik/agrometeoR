---
title: "Benchmarking example"
author: "Thomas Goossens"
date: "11/22/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
devtools::load_all()
```

A benchmark experiment allows to compare how various learners perform one one or multiple tasks.
You can read the full documentation about benchmarking experiment on the [mlr website](https://mlr.mlr-org.com/articles/tutorial/benchmark_experiments.html).

In this vignette we will present you how to use the makeBenchmark function and we will also explore the kind of outputs you can get from it.

But first we will explain why we have decided to implement our custom version of the benchmarking function rather than simply use the mlr one.

## Why create a custom benchmarking function ? 

1. Allow user to have a custom function that is shipped with the package. No need to dig in the extensive mlr documentation for a simple benchmark

2. As we benchmark not a single dataset but plenty of hourly or daily datasets from hour stations network, we need a way to perform, store and analyse thousands of benchmarks while avoiding CPU and RAM saturation.

## Specificities of our benchamrking function

Our benchmarking function ... ::TODO::

## Load the libraries

```{r libraries,results='hide'}
# loading mlr & agrometeoR
library(agrometeoR)
library(mlr)
library(parallelMap)
```


## create the tasks
```{r tasks, results='hide', message=FALSE}
# create an hourly dataset
dataset = makeDataset(dfrom = "2016-07-01T08:00:00Z", dto = "2016-07-01T08:00:00Z")
# create the task
task = makeTask(dataset = dataset$output$value[[1]], target = "tsa")
# each task must be stored in a list element for makeBenchmark function
task = list(task1 = task$output$value)

```

## benchmark some learners on a subset of these tasks

```{r batch_benchmark, message=FALSE, warning=FALSE, results='hide'}
# loading the learners preconfigured with the package
data("learners")
# conduct the bmr on 2 tasks
bmr = makeBenchmark(tasks = task, learners = learners$baseLearners, grouping = 1, cpus = 4, path = "./output/")
```


## vizualize performance 
```{r}
# plotBMRBoxplots(bmr.1core$output$value$bmr, pretty.names = FALSE)
# plotBMRSummary(bmr.1core$output$value$bmr, pretty.names = FALSE)
# 
# lapply(bmrs.1core, function(x) {
#   plotBMRBoxplots(x$output$value[[1]], pretty.names = FALSE)
# })
# 
# lapply(bmrs.1core, function(x) {
#   plotBMRSummary(x$output$value[[1]], pretty.names = FALSE)
# })
```

## Check if parallelization improves computing speed

Let's re-run the same benchmark but on 4 cores this time

```{r parallel, message=FALSE, warning=FALSE, results ='hide' }
# with parallel computing
# bmr.4cores = makeBenchmark(tasks = tasks$output$value[1:3], learners = learners, cpus = 4)
```

We can see that we have an improvement of the computation time of a factor of `#r bmr.1core$output$value$exectime/bmr.4cores$output$value$exectime`

