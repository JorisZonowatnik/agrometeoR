#' @export
#' @title make a multicore parallelized mlr benchmark experiment for various learners on multiple tasks
#' @author Thomas Goossens
#' @import mlr
#' @import parallelMap
#' @importFrom magrittr %>%
#' @param cpus an integer specifying the number of cpus to use for the benchamrk. Default is 1
#' @param tasks a list which elements are object of class mlr::makeRegrTask()
#' @param learners a list which elements are object of class mlr::makeLearner()
#' @param measures a list of the mlr performance metrics you want to get. Default is list(rmse)
#' @param keep.pred a boolean specifying if you want to keep the bmr preds. defaut = TRUE
#' @param models a boolean specifying if you want to keep the bmr models. defaut = FALSE
#' @param grouping a numeric specifying the number of tasks you want to benchamrk in a single batch. Default to 1000
#' @param level a character specifying the paralelllization level. Default  = "mlr.benchmark"
#' @param resampling  a character specifying the type of mlr's Cross-Validation strategy. Default = LOO
#' @param output_dir a character specifying the path of an exising directory where you want to save the bmr outpus.
#' @param prefix a character specifying the prefix you want to use for the bmr file names.
#' @param removeTemp a boolean specifying if the temporary .rds generated by the function must be deleted at the end of the process.
#' Default to FALSE
#' @return a list which elements are objects of class mlr::benchmark()

makeBatchOfBenchExp <- function(
  tasks,
  learners,
  measures = list(rmse),
  keep.pred = TRUE,
  models = FALSE,
  grouping = 1000,
  level = "mlr.benchmark",
  resamplings = "LOO",
  cpus = 1,
  prefix = "",
  output_dir = "bmrs",
  removeTemp = FALSE){

  output = list(value = NULL, condition = list(type = NULL, message = NULL))
  snitch = FALSE

  doBenchmark = function(){

    # set seed to make bmr experiments reproducibles
    set.seed(1985)

    # hack for tasks length when only a single task
    # ::todo::

    # split tasks in multiple subgroups to avoid memory saturation
    if (length(tasks) <= grouping) {
      warning("AgrometeoR warning : length of your tasks list smaller than your grouping parameter.
        Setting the grouping value equal to the length of your tasks. ")
      grouping = length(tasks)
    }

    tasks.groups.start = seq(from = 1, to = length(tasks), by = grouping)
    tasks.groups.end = seq(from = grouping, to = length(tasks), by = grouping)

    # conducting the bmrs by subgroups and writting results to temp .rds file
    lapply(seq_along(as.list(tasks.groups.start)),
      function(x) {


        # message
        message(paste0(
          "Conducting batch of benchmark experiments for tasks " ,
          tasks.groups.start[x], "-",
          tasks.groups.end[x]))

        # enable parallelization with level = mlr.resample
        if (cpus > 1) {
          parallelMap::parallelStart(mode = "multicore", cpus = cpus, level = level)
        }

        # hack to avoid wrong last task number
        if (is.na(tasks.groups.end[x])) {tasks.groups.end[x] = tasks.groups.start[x]}

        # starting counting time of the current bmr execution
        tictoc::tic()

        # benchmark
        bmr = mlr::benchmark(
          learners = learners,
          tasks = tasks[tasks.groups.start[x]:tasks.groups.end[x]],
          resamplings = mlr::makeResampleDesc(resamplings),
          measures = measures,
          keep.pred = keep.pred,
          models = models)

        # stoping counting time
        exectime = tictoc::toc()
        exectime = exectime$toc - exectime$tic

        # stop the parallelized computing
        if (cpus > 1) {
          parallelMap::parallelStop()
        }

        # save the bmr object to a file with creation of directory if not existing
        if (!dir.exists(output_dir)) {
          dir.create(
            paste0(output_dir))
        }
        saveRDS(object = bmr, file = paste0(output_dir,
          "/",
          prefix,
          "_bmr_",
          mlr::getTaskId(tasks[[tasks.groups.start[x]]]),
          "_",
          mlr::getTaskId(tasks[[tasks.groups.end[x]]]),
          ".rds"))

        # remove the object stored in RAM
        rm(bmr)

        # success message
        message(paste0(
          "Results of batch of Benchmark experiments for tasks " ,
          mlr::getTaskId(tasks[[tasks.groups.start[x]]]), " - ",
          mlr::getTaskId(tasks[[tasks.groups.end[x]]]), " conducted and written to file. "))

      })

        # loading all the temp bmr files and merging in a single big bmr object
        bmr_files = list.files(path = output_dir, pattern = prefix, full.names = TRUE)
        bmrs = lapply(bmr_files, readRDS)

        # deleting temporary .rds files is removeTemp = true
        if (isTRUE(removeTemp)) {
          file.remove(bmr_files)
        }

        if (length(bmrs) > 1) {bmrs = mergeBenchmarkResults(bmrs)}
        else {bmrs = bmrs[[1]]}

        # perfs + aggregated Performances
        bmrs = bmrs
        perfs = getBMRPerformances(bmrs, as.df = TRUE)
        aggPerfs = getBMRAggrPerformances(bmrs, as.df = TRUE)
        rmse_summary = aggPerfs %>%
          dplyr::group_by(learner.id) %>%
          dplyr::select(rmse.test.rmse) %>%
          dplyr::summarise_all(
            funs(count = sum(!is.na(.)),
              min = min(.,na.rm = TRUE),
              max = max(.,na.rm = TRUE),
              mean = mean(.,na.rm = TRUE),
              median = median(.,na.rm = TRUE),
              sd = sd(.,na.rm = TRUE)))

        # Throw a success message
        message("Success, batch of benchmark experiment conducted")

        # return all the bmr results in a list
        return(batchOfBenchmarkExp = list(
          bmrs = bmrs,
          aggPerfs = aggPerfs,
          rmse_summary = rmse_summary,
          residuals = residuals
        ))
  }

  tryCatch(
    expr = {
      # add checks
      # ::TODO:

      # in case everything went fine, do makeBatchOfBenchExp
      output$value = doBenchmark()
      output$condition$type = "success"
      output$condition$message = "Dataset created"
      snitch = TRUE

    },
    warning = function(w){
      warning = paste0(
        "AgrometeoR::makeBatchOfBenchExp raised a warning -> ",
        w)
      snitch <<- TRUE
      output$value <<- doBenchmark()
      output$condition$type <<- "warning"
      output$condition$message <<- warning
    },
    error = function(e){
      error = paste0(
        "AgrometeoR::makeBatchOfBenchExp raised an error -> ",
        e)
      output$condition$type <<- "error"
      output$condition$message <<- error
    },
    finally = {
      finalMessage = paste0(
        "makeBatchOfBenchExp has encountered : ",
        output$condition$type,
        ". \n",
        "All done with makeBatchOfBenchExp "
      )
      message(finalMessage)
      return(list(snitch = snitch, output = output))
    }
  )
}




